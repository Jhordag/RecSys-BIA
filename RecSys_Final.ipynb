{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<h1> Grupo Xurrasco </h1>\n",
        "\n",
        "Gabriel Jhordan\n",
        "\n",
        "Pedro Augusto"
      ],
      "metadata": {
        "id": "aaDTfcc_ZXsv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Clone do GiT"
      ],
      "metadata": {
        "id": "xfv0vezwZje8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Jhordag/RecSys-BIA.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "duqfkHL6Y7d8",
        "outputId": "93f81505-8799-40c8-8045-c7539f49bef2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'RecSys-BIA'...\n",
            "remote: Enumerating objects: 25, done.\u001b[K\n",
            "remote: Counting objects: 100% (25/25), done.\u001b[K\n",
            "remote: Compressing objects: 100% (19/19), done.\u001b[K\n",
            "remote: Total 25 (delta 5), reused 24 (delta 4), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (25/25), 25.04 MiB | 9.80 MiB/s, done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Baixando as bibliotecas necessarias"
      ],
      "metadata": {
        "id": "0HIdVKYcaL8m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r /content/RecSys-BIA/requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rjq_WLGfY7Ti",
        "outputId": "84119d75-73bd-4629-bb5f-d8fc29f7cd2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers==4.17.0\n",
            "  Downloading transformers-4.17.0.tar.gz (3.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m39.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from -r /content/RecSys-BIA/requirements.txt (line 2)) (4.64.1)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement nmslib==23.0 (from versions: 1.6.3, 1.7, 1.7.1, 1.7.2, 1.7.3.1, 1.7.3.2, 1.7.3.3, 1.7.3.4, 1.7.3.6, 1.8, 1.8.1, 2.0.4, 2.0.5, 2.0.6, 2.1.1)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for nmslib==23.0\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install simplejson\n",
        "!pip install sentence-transformers\n",
        "!pip install --no-binary :all: nmslib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_uHi1FfwrWAD",
        "outputId": "3b7d3bb3-c757-4b2b-ff57-a3500d3cd8ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting simplejson\n",
            "  Downloading simplejson-3.18.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (135 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.5/135.5 KB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: simplejson\n",
            "Successfully installed simplejson-3.18.3\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sentence-transformers\n",
            "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 KB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting transformers<5.0.0,>=4.6.0\n",
            "  Downloading transformers-4.26.1-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m49.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from sentence-transformers) (4.64.1)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from sentence-transformers) (1.13.1+cu116)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.8/dist-packages (from sentence-transformers) (0.14.1+cu116)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from sentence-transformers) (1.21.6)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (from sentence-transformers) (1.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from sentence-transformers) (1.7.3)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.8/dist-packages (from sentence-transformers) (3.7)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.97-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m55.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting huggingface-hub>=0.4.0\n",
            "  Downloading huggingface_hub-0.12.1-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (23.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.5.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.9.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.25.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2022.6.2)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m49.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from nltk->sentence-transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from nltk->sentence-transformers) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->sentence-transformers) (3.1.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.8/dist-packages (from torchvision->sentence-transformers) (7.1.2)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (1.24.3)\n",
            "Building wheels for collected packages: sentence-transformers\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125938 sha256=7676f0cef0095c0aad2944caedccafa6dc369eeb261b3ed418fbdbae7c137cbe\n",
            "  Stored in directory: /root/.cache/pip/wheels/5e/6f/8c/d88aec621f3f542d26fac0342bef5e693335d125f4e54aeffe\n",
            "Successfully built sentence-transformers\n",
            "Installing collected packages: tokenizers, sentencepiece, huggingface-hub, transformers, sentence-transformers\n",
            "Successfully installed huggingface-hub-0.12.1 sentence-transformers-2.2.2 sentencepiece-0.1.97 tokenizers-0.13.2 transformers-4.26.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting nmslib\n",
            "  Downloading nmslib-2.1.1.tar.gz (188 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 KB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pybind11<2.6.2\n",
            "  Downloading pybind11-2.6.1.tar.gz (171 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m171.6/171.6 KB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.8/dist-packages (from nmslib) (5.4.8)\n",
            "Requirement already satisfied: numpy>=1.10.0 in /usr/local/lib/python3.8/dist-packages (from nmslib) (1.21.6)\n",
            "Skipping wheel build for nmslib, due to binaries being disabled for it.\n",
            "Building wheels for collected packages: pybind11\n",
            "  Building wheel for pybind11 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pybind11: filename=pybind11-2.6.1-py2.py3-none-any.whl size=188544 sha256=c779b224eed313a11d4977c1173d77a76afc49f47b7dcb1a5c9e0f4b38dad95f\n",
            "  Stored in directory: /root/.cache/pip/wheels/e0/9c/78/5255c70a7a920f53ee026adab1e011b41f7bd6365dffda6d17\n",
            "Successfully built pybind11\n",
            "Installing collected packages: pybind11, nmslib\n",
            "  Running setup.py install for nmslib ... \u001b[?25l\u001b[?25hdone\n",
            "Successfully installed nmslib-2.1.1 pybind11-2.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Gerando arquivo  csv\n",
        "\n",
        "Como o demorar muito rodar o csv pode apenas ser baixado de na celula abaixo"
      ],
      "metadata": {
        "id": "GDvZa1Sik0aI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install --upgrade --no-cache-dir gdown"
      ],
      "metadata": {
        "id": "3A6ef2vVk7hI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!gdown https://drive.google.com/u/0/uc?id=1HSqomIYUvX7lvbI3S-DPzg0c4Y_Y0jbK"
      ],
      "metadata": {
        "id": "93IQB2awk7HL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!tar -xf /content/yelp_dataset.tar"
      ],
      "metadata": {
        "id": "YNLAOEmzmAYG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Extraindo \"yelp_academic_dataset_business.csv\" "
      ],
      "metadata": {
        "id": "s6fgI4Kvbw5A"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DETMr8d_Y4MC",
        "outputId": "bea33938-ebd7-4dfe-85ca-04e4f05e5790"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/RecSys-BIA/dataset.zip\n",
            "   creating: dataset/\n",
            "  inflating: dataset/yelp_academic_dataset_business.csv  \n"
          ]
        }
      ],
      "source": [
        "!unzip /content/RecSys-BIA/dataset.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pre-Processamento dos dados"
      ],
      "metadata": {
        "id": "lHi6NN5dmZOe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/RecSys-BIA/processamento.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cwkf6At_mU24",
        "outputId": "cdf65d52-2f00-4eff-e086-1a5709c19a52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sys:1: DtypeWarning: Columns (23,34) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "/content/RecSys-BIA/processamento.py:49: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['stars'][index] = 'good'\n",
            "/usr/local/lib/python3.8/dist-packages/pandas/core/indexing.py:1732: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self._setitem_single_block(indexer, value, name)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gerando os embeddings com o sentence_transformer"
      ],
      "metadata": {
        "id": "h0QCcmY8pvs_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir output_path"
      ],
      "metadata": {
        "id": "2nJu6vyImUqz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/RecSys-BIA/baseline/extract_sentence_transformer.py sentence-transformers/all-MiniLM-L6-v2 '/content/dataset/df_categories.csv' output_path"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6dD_oGeqxgU",
        "outputId": "442b1ac2-c1a8-4cb6-b626-6c7d78cc8983"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-02-21 21:19:03.242878: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-02-21 21:19:04.171820: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-02-21 21:19:04.171932: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-02-21 21:19:04.171951: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "\n",
            "\n",
            "Load Dataset...\n",
            "              business_id  ...                                           features\n",
            "0  Pns2l4eNsfO8kk83dixA6A  ...  Abby Rappoport, LAC, CMQ Health & Medical,Doct...\n",
            "1  mpf3x-BjTdTEA3yCZrAYPw  ...  The UPS Store Local Services,Shipping Centers ...\n",
            "2  tUFrWirKiKi_TAnsVWINQQ  ...  Target Shopping,Home & Garden and Fashion neut...\n",
            "3  MTSW4McQd7CbVtyjqoe9mw  ...  St Honore Pastries Restaurants,Food and Coffee...\n",
            "4  mWMc6_wTdE0EUBKIGXDVfA  ...  Perkiomen Valley Brewery Food,Breweries and Br...\n",
            "\n",
            "[5 rows x 4 columns]\n",
            "\n",
            "\n",
            "Load Transform Model...\n",
            "Downloading (…)e9125/.gitattributes: 100% 1.18k/1.18k [00:00<00:00, 185kB/s]\n",
            "Downloading (…)_Pooling/config.json: 100% 190/190 [00:00<00:00, 29.7kB/s]\n",
            "Downloading (…)7e55de9125/README.md: 100% 10.6k/10.6k [00:00<00:00, 4.20MB/s]\n",
            "Downloading (…)55de9125/config.json: 100% 612/612 [00:00<00:00, 245kB/s]\n",
            "Downloading (…)ce_transformers.json: 100% 116/116 [00:00<00:00, 48.2kB/s]\n",
            "Downloading (…)125/data_config.json: 100% 39.3k/39.3k [00:00<00:00, 637kB/s]\n",
            "Downloading (…)\"pytorch_model.bin\";: 100% 90.9M/90.9M [00:00<00:00, 235MB/s]\n",
            "Downloading (…)nce_bert_config.json: 100% 53.0/53.0 [00:00<00:00, 8.63kB/s]\n",
            "Downloading (…)cial_tokens_map.json: 100% 112/112 [00:00<00:00, 43.6kB/s]\n",
            "Downloading (…)e9125/tokenizer.json: 100% 466k/466k [00:00<00:00, 1.88MB/s]\n",
            "Downloading (…)okenizer_config.json: 100% 350/350 [00:00<00:00, 128kB/s]\n",
            "Downloading (…)9125/train_script.py: 100% 13.2k/13.2k [00:00<00:00, 5.13MB/s]\n",
            "Downloading (…)7e55de9125/vocab.txt: 100% 232k/232k [00:00<00:00, 929kB/s]\n",
            "Downloading (…)5de9125/modules.json: 100% 349/349 [00:00<00:00, 133kB/s]\n",
            "SentenceTransformer(\n",
            "  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False}) with Transformer model: BertModel \n",
            "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n",
            "  (2): Normalize()\n",
            ")\n",
            "\n",
            "\n",
            "Extract Embeddings...\n",
            "100% 150346/150346 [19:37<00:00, 127.65it/s]\n",
            "              business_id  ...                                               embs\n",
            "0  Pns2l4eNsfO8kk83dixA6A  ...  [-0.02887655, -0.05925571, 0.042264927, 0.1208...\n",
            "1  mpf3x-BjTdTEA3yCZrAYPw  ...  [-0.1050691, -0.0145857325, -0.10099261, 0.011...\n",
            "2  tUFrWirKiKi_TAnsVWINQQ  ...  [0.015552839, 0.024665851, -0.012300357, 0.034...\n",
            "3  MTSW4McQd7CbVtyjqoe9mw  ...  [0.0043798788, 0.066017285, 0.013398082, 0.030...\n",
            "4  mWMc6_wTdE0EUBKIGXDVfA  ...  [0.021631772, 0.023729661, -0.005847354, 0.019...\n",
            "\n",
            "[5 rows x 5 columns]\n",
            "\n",
            "\n",
            "Extract Dataset...\n",
            "\n",
            "\n",
            "Done! :)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Avaliação dos Modelos"
      ],
      "metadata": {
        "id": "ngZ0dzoMsaWs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/RecSys-BIA/evaluation/evaluation.py /content/output_path/embeddings.txt /content/output_path/metadados.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2X66b7BZseHn",
        "outputId": "a7115875-a13f-491e-f5b8-7ee48b46321b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0%   10   20   30   40   50   60   70   80   90   100%\n",
            "|----|----|----|----|----|----|----|----|----|----|\n",
            "***************************************************\n",
            "\n",
            "0%   10   20   30   40   50   60   70   80   90   100%\n",
            "|----|----|----|----|----|----|----|----|----|----|\n",
            "***************************************************\n",
            "*              business_id  ...                                           features\n",
            "0  Pns2l4eNsfO8kk83dixA6A  ...  Abby Rappoport, LAC, CMQ Health & Medical,Doct...\n",
            "1  mpf3x-BjTdTEA3yCZrAYPw  ...  The UPS Store Local Services,Shipping Centers ...\n",
            "2  tUFrWirKiKi_TAnsVWINQQ  ...  Target Shopping,Home & Garden and Fashion neut...\n",
            "3  MTSW4McQd7CbVtyjqoe9mw  ...  St Honore Pastries Restaurants,Food and Coffee...\n",
            "4  mWMc6_wTdE0EUBKIGXDVfA  ...  Perkiomen Valley Brewery Food,Breweries and Br...\n",
            "\n",
            "[5 rows x 4 columns]\n",
            "1000it [00:01, 994.31it/s]\n",
            "\n",
            "\n",
            "Avaliação de Embeddings\n",
            "Embeddings:  /content/output_path/embeddings.txt\n",
            "Total Users:  1000\n",
            "NDCG@5:  0.6501589166050685\n",
            "NDCG@10:  0.7065891490959887\n"
          ]
        }
      ]
    }
  ]
}